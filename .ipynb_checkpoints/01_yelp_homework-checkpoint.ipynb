{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework with Yelp reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This assignment uses a small subset of the data from Kaggle's [Yelp Business Rating Prediction](https://www.kaggle.com/c/yelp-recsys-2013) competition.\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.csv`** contains the dataset. It is stored in the course repository (in the **`data`** directory), so there is no need to download anything from the Kaggle website.\n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "- The **cool** column is the number of \"cool\" votes this review received from other Yelp users. All reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n",
    "- The **useful** and **funny** columns are similar to the **cool** column.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text. (We will not be using the cool, funny, or useful columns.)\n",
    "\n",
    "**Tip:** After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **`yelp.csv`** into a Pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/SamK/Desktop/MLTextEx/data/yelp.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n",
    "- **Hint:** You will need to filter the DataFrame using an OR condition. [Working with DataFrames](http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes/) has an example of this, and this [code snippet](http://chrisalbon.com/python/pandas_select_rows_multiple_filters.html) may also be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new new dataframe with only star ratings of 1 and 5\n",
    "ydf = pd.DataFrame(df[(df.stars == 5) | (df.stars == 1)])\n",
    "ydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n",
    "- **Hint:** Keep in mind that X should be a Pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "# define X and y for new data frame\n",
    "X = ydf.text\n",
    "y = ydf.stars\n",
    "\n",
    "# import train_test_split module and split data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create **document-term matrices** from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CountVectorizer to create document-term matrices for X_trian and X_test\n",
    "# vect.fit(X_train) creates a vocabulary for the dataset\n",
    "# vect.transform(X_train) creates a documet-term-matrix for the data using fitted vocabulary\n",
    "# vect.transform(X_test) creates a document-term-matrix for the test set using vocabulary from X_train\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# vect.fit(X_train)\n",
    "# X_train_dtm = vect.transform(X_train)\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 77006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use Multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import multinomial naive bayes and instatiate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 1, 5])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the training_dtm data and predict star rating\n",
    "nb.fit(X_train_dtm, y_train) # what is the reason for using X_train_dtm instead of X_train?\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "y_pred_class # why is this an array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91878669275929548"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,  58],\n",
       "       [ 25, 813]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "# how does the array choose whether 1 is first (is it numeric order)?\n",
    "# true positives (rating was 1, predicted 1): 126\n",
    "# false positives (rating was 1, predicted 5): 58\n",
    "# false negatives (rating was 5, predicted 1): 25\n",
    "# true negatives (rating was 5, predicted 5): 813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (Challenge)\n",
    "\n",
    "Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.819961\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does \"class\" mean the rating 5 is one class and 1 is another class?\n",
    "\n",
    "y_test.value_counts().head(1) / len(y_test)\n",
    "\n",
    "# NB is better predictor of rating than just using null accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "Browse through the review text of some of the **false positives** and **false negatives**. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains the definitions of \"false positives\" and \"false negatives\".\n",
    "- **Hint:** Think about what a false positive means in this context, and what a false negative means in this context. What has scikit-learn defined as the \"positive class\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "2674    I'm sorry to be what seems to be the lone one ...\n",
       "9984    Went last night to Whore Foods to get basics t...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "8283    Don't know where I should start. Grand opening...\n",
       "2765    Went last week, and ordered a dozen variety. I...\n",
       "2839    Never Again,\\nI brought my Mountain Bike in (w...\n",
       "321     My wife and I live around the corner, hadn't e...\n",
       "1919                                         D-scust-ing.\n",
       "2490    Lazy Q CLOSED in 2010.  New Owners cleaned up ...\n",
       "9125    La Grande Orange Grocery has a problem. It can...\n",
       "9185    For frozen yogurt quality, I give this place a...\n",
       "436     this another place that i would give no stars ...\n",
       "2051    Sadly with new owners comes changes on menu.  ...\n",
       "1721    This is the closest to a New York hipster styl...\n",
       "3447    If you want a school that cares more about you...\n",
       "842     Boy is the name a temptation.Seriously :)  I'l...\n",
       "6159    Really, if I could, I would give this place ze...\n",
       "943     Don't waste your time...Arrowhead mall on the ...\n",
       "5977    You want good food? You'd be better off smuggl...\n",
       "8833    The owner has changed hands & this place isn't...\n",
       "6584    Jimmy Johns is cheaper and better ... The Capr...\n",
       "1899    Buca Di Beppo is literally, italian restaurant...\n",
       "9953    \"Hipster,Trendy\" ????-I think NOT !!!! Very di...\n",
       "2060                This place is closed.  Good riddance.\n",
       "3082    Currently having a liquidation sale, but it's ...\n",
       "8220    Maybe I ate at a different restaurant than the...\n",
       "3634    Seriously?! With grocery stores like Fresh & E...\n",
       "3266    Absolutely awful... these guys have NO idea wh...\n",
       "7397    This place sucks!! I moved to the valley and h...\n",
       "4473    It is what you would expect from any themed pl...\n",
       "5502    Angry Bro Bar !  Please go here if you wear si...\n",
       "2615    Great in its day, now leaves a lot to be desir...\n",
       "3413    I purchased the Enotria groupon when it was re...\n",
       "2999    I can't even believe I actually went to this r...\n",
       "1372    No offense to everyone who gave this place 5 s...\n",
       "1291    Every time I come here the staff is so rude! I...\n",
       "6222    My mother always told me, if I didn't have any...\n",
       "9296    My boyfriend and I tried this place last year ...\n",
       "7975    What are you all talking about?! This place is...\n",
       "4630    I used to always go here for tires until my me...\n",
       "7130    I was not impressed. The food was bad & expens...\n",
       "5818    Most horrible buffet I have ever been to.\\n\\nM...\n",
       "3704    Staff is nice, and that's it.\\nThey use very c...\n",
       "8741    They served us stale rice.  Average main dishe...\n",
       "3938    We were so disappointed!  We were on vacation ...\n",
       "7631    this is a business located in the fry's grocer...\n",
       "8681    As I promised myself, I'd go back again to try...\n",
       "1532    Cold, under done chips. If a Mexican food rest...\n",
       "113     Unless you are a regular or look like your wal...\n",
       "4165    OMG! what is the rave about? this place is dis...\n",
       "9299    The salad plates were not chilled... As they u...\n",
       "4311    Donuts are really good, if they have any when ...\n",
       "7035    Totally excited to try this place out, my gran...\n",
       "8000    Still a place that is unacceptable in my book-...\n",
       "3755    Have been going to LGO since 2003 and have alw...\n",
       "507     HELLISH HELLISH SUMMER WEATHER (March thru Oct...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scitkit has defined 1 as the positive class and 5 as the negative class\n",
    "# the model is incorrectly classifying reviews that are very long and consist of a mix of positive and negative words/tokens\n",
    "\n",
    "# false positives\n",
    "X_testfp = X_test[y_test < y_pred_class]\n",
    "X_testfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donuts are really good, if they have any when you get there!!!  Went in on a Tuesday morning at 1030, and they only had a total of 10 donuts. Drove out of my way to go there and still ended up at Dunkin Donuts. Very disappointed!!'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testfp[4311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "4963    This is by far my favourite department store, ...\n",
       "6318    Since I have ranted recently on poor customer ...\n",
       "380     This is a must try for any Mani Pedi fan. I us...\n",
       "5565    I`ve had work done by this shop a few times th...\n",
       "3448    I was there last week with my sisters and whil...\n",
       "6050    I went to sears today to check on a layaway th...\n",
       "2504    I've passed by prestige nails in walmart 100s ...\n",
       "2475    This place is so great! I am a nanny and had t...\n",
       "241     I was sad to come back to lai lai's and they n...\n",
       "3149    I was told to see Greg after a local shop diag...\n",
       "423     These guys helped me out with my rear windshie...\n",
       "763     Here's the deal. I said I was done with OT, bu...\n",
       "8956    I took my computer to RedSeven recently when m...\n",
       "750     This store has the most pleasant employees of ...\n",
       "9765    You can't give anything less than 5 stars to a...\n",
       "6334    I came here today for a manicure and pedicure....\n",
       "1282    Loved my haircut. Walked in and waited for jus...\n",
       "1266    I've never been to this location before. My hu...\n",
       "402     Once again Wildflower proves why it's my favor...\n",
       "4034    \"Fine dining\" is not just a setting.  it isn't...\n",
       "2444    EXCELLENT CUSTOMER SERVICE! \\n\\nEven with Happ...\n",
       "2494    What a great surprise stumbling across this ba...\n",
       "5736    Thank goodness for Sue at Mill Avenue Travel. ...\n",
       "7903    First, I'm sorry this review is lengthy, but i...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negatives (rating was 5, predicted 1)\n",
    "\n",
    "X_testfn = X_test[y_test > y_pred_class]\n",
    "X_testfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First, I\\'m sorry this review is lengthy, but i really want people to understand how far a little kindness can go. \\n\\nI entered Mimi\\'s Cafe at the end of possibly worst day ever. I came in looking to order food for takeout and get home to drown my sorrows in comfort food. i was directed by the hostess up front to go stand by the bakery and i would be able to order take out. i waited not 15 seconds and was greeted with a huge smile from a lovely girl named Danielle. She gave me a menu and told me to ask if i had questions and inquired if i had been there before. i looked at the menu for some time, unable to clear my mind enough to decide. She told me i was welcome to take a seat, and when i apologized for taking so long she responded with a smiley \"where\\'s the fire? take your time, can i get you a glass of wine while you decide?\" wine was a perfect idea! I finally ordered and sat drinking my wine. i waited, and then waited a little longer, Danielle the young girl doing take out informed me the kitchen was working as fast as they could but are very busy, she apologized for the wait and offered complimentary bread  and convinced me to buy a a second glass of wine. When she brought me the second glass i had just gotten off the phone and was visibly shaken with more bad news. Somehow this young girl had the courage to ask if everything was alright and what she could do to help. It was just the olive branch i needed. Just the inquiry was enough to make me feel better. i told her i was fine and thanked her for her compassion. finally my food was ready. She boxed everything with care for the drive home. All this time smiling. i couldn\\'t help but notice Danielle interact with the other employees they always laughed or high fived her with each exchange. She had brightened my day, and it was clear she is a light for others in Mimi\\'s Cafe. This is the kicker...my bill was $30 and some change...i gave her what i thought was two $20 dollar bills, but in reality was a $50 and a $20. The young girl ran outside and stopped me saying sir, I\\'m not sure these bills are right. i was overwhelmed by her honesty and told her no, i thought they were two 20\\'s but the difference would be her reward for honesty. The food was tasty and just what i needed. Mimi\\'s Cafe is a friendly place worth the wait for food or a table, and if Mimi\\'s Cafe reads these reviews know that you have a superstar in Danielle.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testfn[7903]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "\n",
    "Calculate which 10 tokens are the most predictive of **5-star reviews**, and which 10 tokens are the most predictive of **1-star reviews**.\n",
    "\n",
    "- **Hint:** Naive Bayes automatically counts the number of times each token appears in each class, as well as the number of observations in each class. You can access these counts via the `feature_count_` and `class_count_` attributes of the Naive Bayes model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'zwiebel', u'zzed', u'\\xe9clairs', u'\\xe9cole', u'\\xe9m']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the feature names for train tokens\n",
    "\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "X_train_tokens[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26.,   4.,   1., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use feature_count_ to count the numbe of tokens in class 1 and class 5\n",
    "# i am not sure if my assumption that 1 is 0 is correct\n",
    "token_count_1 = nb.feature_count_[0,:]\n",
    "token_count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39.,   5.,   0., ...,   1.,   1.,   1.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count_5 = nb.feature_count_[1,:]\n",
    "token_count_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26.,   4.,   1., ...,   0.,   0.,   0.],\n",
       "       [ 39.,   5.,   0., ...,   1.,   1.,   1.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00am</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00pm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1     5\n",
       "tokens            \n",
       "00      26.0  39.0\n",
       "000      4.0   5.0\n",
       "00a      1.0   0.0\n",
       "00am     3.0   2.0\n",
       "00pm     1.0   4.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pd.DataFrame({'tokens':X_train_tokens, '1':token_count_1, '5':token_count_5}).set_index('tokens')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  565.,  2499.])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>5_freq</th>\n",
       "      <th>1_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00am</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00pm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1     5  5_freq  1_freq\n",
       "tokens                            \n",
       "00      26.0  39.0    40.0    27.0\n",
       "000      4.0   5.0     6.0     5.0\n",
       "00a      1.0   0.0     1.0     2.0\n",
       "00am     3.0   2.0     3.0     4.0\n",
       "00pm     1.0   4.0     5.0     2.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['5_freq'] = tokens['5'] + 1\n",
    "tokens['1_freq'] = tokens['1'] + 1\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>5_freq</th>\n",
       "      <th>1_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.264074e-19</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.089611e-19</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.816019e-20</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00am</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.448056e-20</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00pm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.080093e-20</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1     5        5_freq    1_freq\n",
       "tokens                                    \n",
       "00      26.0  39.0  7.264074e-19  0.000085\n",
       "000      4.0   5.0  1.089611e-19  0.000016\n",
       "00a      1.0   0.0  1.816019e-20  0.000006\n",
       "00am     3.0   2.0  5.448056e-20  0.000013\n",
       "00pm     1.0   4.0  9.080093e-20  0.000006"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['5_freq'] = tokens['5_freq'] / nb.class_count_[1]\n",
    "tokens['1_freq'] = tokens['1_freq'] / nb.class_count_[0]\n",
    "tokens.head()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>5_freq</th>\n",
       "      <th>1_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4175.0</td>\n",
       "      <td>14008.0</td>\n",
       "      <td>2.544060e-16</td>\n",
       "      <td>0.013082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2659.0</td>\n",
       "      <td>10429.0</td>\n",
       "      <td>1.894107e-16</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2409.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>1.150266e-16</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1294.0</td>\n",
       "      <td>4557.0</td>\n",
       "      <td>8.277412e-17</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>770.0</td>\n",
       "      <td>4390.0</td>\n",
       "      <td>7.974137e-17</td>\n",
       "      <td>0.002415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1328.0</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>7.736239e-17</td>\n",
       "      <td>0.004163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>6.419625e-17</td>\n",
       "      <td>0.004652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>941.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>6.332457e-17</td>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>970.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>6.021917e-17</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>637.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>5.271902e-17</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1        5        5_freq    1_freq\n",
       "tokens                                         \n",
       "the     4175.0  14008.0  2.544060e-16  0.013082\n",
       "and     2659.0  10429.0  1.894107e-16  0.008333\n",
       "to      2409.0   6333.0  1.150266e-16  0.007550\n",
       "of      1294.0   4557.0  8.277412e-17  0.004057\n",
       "is       770.0   4390.0  7.974137e-17  0.002415\n",
       "it      1328.0   4259.0  7.736239e-17  0.004163\n",
       "was     1484.0   3534.0  6.419625e-17  0.004652\n",
       "in       941.0   3486.0  6.332457e-17  0.002951\n",
       "for      970.0   3315.0  6.021917e-17  0.003042\n",
       "you      637.0   2902.0  5.271902e-17  0.001999"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values('5_freq', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>5_freq</th>\n",
       "      <th>1_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4175.0</td>\n",
       "      <td>14008.0</td>\n",
       "      <td>2.544060e-16</td>\n",
       "      <td>0.013082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2659.0</td>\n",
       "      <td>10429.0</td>\n",
       "      <td>1.894107e-16</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2409.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>1.150266e-16</td>\n",
       "      <td>0.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>1484.0</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>6.419625e-17</td>\n",
       "      <td>0.004652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1328.0</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>7.736239e-17</td>\n",
       "      <td>0.004163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1294.0</td>\n",
       "      <td>4557.0</td>\n",
       "      <td>8.277412e-17</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>970.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>6.021917e-17</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>958.0</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>4.707120e-17</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>941.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>6.332457e-17</td>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>841.0</td>\n",
       "      <td>2689.0</td>\n",
       "      <td>4.885090e-17</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1        5        5_freq    1_freq\n",
       "tokens                                         \n",
       "the     4175.0  14008.0  2.544060e-16  0.013082\n",
       "and     2659.0  10429.0  1.894107e-16  0.008333\n",
       "to      2409.0   6333.0  1.150266e-16  0.007550\n",
       "was     1484.0   3534.0  6.419625e-17  0.004652\n",
       "it      1328.0   4259.0  7.736239e-17  0.004163\n",
       "of      1294.0   4557.0  8.277412e-17  0.004057\n",
       "for      970.0   3315.0  6.021917e-17  0.003042\n",
       "that     958.0   2591.0  4.707120e-17  0.003004\n",
       "in       941.0   3486.0  6.332457e-17  0.002951\n",
       "my       841.0   2689.0  4.885090e-17  0.002638"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values('1_freq', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "Up to this point, we have framed this as a **binary classification problem** by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a **5-class classification problem**.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "- Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "- Split X and y into training and testing sets.\n",
    "- Create document-term matrices using CountVectorizer.\n",
    "- Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy, and comment on the results.\n",
    "- Print the confusion matrix, and comment on the results.\n",
    "- Print the [classification report](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), and comment on the results. If you are unfamiliar with the terminology it uses, research the terms, and then try to figure out how to calculate these metrics manually from the confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df.text\n",
    "y = df.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create document-term matrices using CountVectorizer\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47120000000000001"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate testing accuracy\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "y_pred_class\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55,  14,  24,  65,  27],\n",
       "       [ 28,  16,  41, 122,  27],\n",
       "       [  5,   7,  35, 281,  37],\n",
       "       [  7,   0,  16, 629, 232],\n",
       "       [  6,   4,   6, 373, 443]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class) # how would you read this confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    884\n",
       "5    832\n",
       "3    365\n",
       "2    234\n",
       "1    185\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.3536\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare testing accuracy with null accuracy\n",
    "y_test.value_counts().head(1) / len(y_test)\n",
    "\n",
    "# Even though the 47% classification accuracy score is quite low. it is still better than just predicting the most frequently occuring class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
